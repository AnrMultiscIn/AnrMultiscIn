<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ANR - Highlights</title>
  <meta name="description" content="ANR -- Publications.">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/publications/">
<link rel="shortcut icon" type ="image/x-icon" href="http://localhost:4000/images/favicon.ico">



</head>


  <body>


  
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="http://localhost:4000/">ANR Multisc'in</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<!-- <li><a href="http://localhost:4000/about">About</a></li> -->
		<li><a href="http://localhost:4000/team">Team</a></li>
		<!-- <li><a href="http://localhost:4000/vacancies">Vacancies</a></li> -->
		<li><a href="http://localhost:4000/publications">Publications</a></li>
		<li><a href="http://localhost:4000/research">Codes & Datasets</a></li>
		<!-- <li><a href="http://localhost:4000/webinar">Meetings</a></li> -->
		<!-- <li><a href="http://localhost:4000/training">Training</a></li> -->
	  </ul>
	</div>
  </div>
</div>

  

    <div class="container-fluid">
      <div class="row">
        <div id="gridid" class="col-sm-12">
  <h1 id="publications">Publications</h1>

<h2 id="group-highlights">Group highlights</h2>

<div class="col">

  <div class="well">
    <p><em>Hoang Trieu Vy Le, Marion Foare, Nelly Pustelnik</em></p>
    <pubtit>Proximal based strategies for solving discrete Mumford-Shah with Ambrosio-Tortorelli penalization on edges</pubtit>
    <p><img src="http://localhost:4000/images/pubpic/SPL_2022a.png" class="img-responsive" width="30%" style="float: left" /></p>
    <p>This work is dedicated to joint image restoration and contour detection considering the Ambrosio-Tortorelli functional. Two proximal alternating minimization schemes with convergence guarantees are provided, PALM-AT and SL-PAM-AT, as well as closed-form expressions of the involved proximity operators. A thorough numerical study is conducted in order to evaluate the performance of both numerical schemes as well as comparisons to state-of-the-art Mumford-Shah strategies.</p>
    <p><strong><a href="https://ieeexplore.ieee.org/abstract/document/9723590">[pdf]</a></strong></p>

    <p><strong><a href="https://github.com/hoangtrieuvy/GGS-DMS">[Source code]</a></strong></p>

    <p class="text-danger"><strong> </strong></p>
    <p> </p>
  </div>

  <div class="col">

    <div class="well">
      <p><em>C.G. Lucas, B. Pascal, N. Pustelnik, and P. Abry</em></p>
      <pubtit>Hyperparameter selection for the Discrete Mumford-Shah functional</pubtit>
      <p><img src="http://localhost:4000/images/pubpic/SIVP2022.png" class="img-responsive" width="30%" style="float: left" /></p>
      <p>This work focuses on a parameter-free joint piecewise smooth image denoising and contour detection. Formulated as the minimization of a discrete Mumford-Shah functional and estimated via a theoretically grounded alternating minimization scheme, the bottleneck of such a variational approach lies in the need to fine-tune their hyperparameters, while not having access to ground truth data. To that aim, a Stein-like strategy providing optimal hyperparameters is designed, based on the minimization of an unbiased estimate of the quadratic risk. Efficient and automated minimization of the estimate of the risk crucially relies on an unbiased estimate of the gradient of the risk with respect to hyperparameters. Its practical implementation is performed using a forward differentiation of the alternating scheme minimizing the Mumford-Shah functional, requiring exact differentiation of the proximity operators involved. Intensive numerical experiments are performed on synthetic images with different geometry and noise levels, assessing the accuracy and the robustness of the proposed procedure. The resulting parameter-free piecewise-smooth estimation and contour detection procedure, not requiring prior image processing expertise nor annotated data, can then be applied to real-world images.</p>
      <p><strong><a href="">Signal, Image and Video Processing, pp.1-8, Dec. 2022.</a></strong></p>

      <p class="text-danger"><strong> </strong></p>
      <p> </p>
    </div>

    <div class="col">

      <div class="well">
        <p><em>L. M. Briceño-Arias and N. Pustelnik</em></p>
        <pubtit>Theoretical and numerical comparison of first order algorithms for cocoercive equations and smooth convex optimization</pubtit>
        <p><img src="http://localhost:4000/images/pubpic/SP2023.png" class="img-responsive" width="30%" style="float: left" /></p>
        <p>In this paper we provide a theoretical and numerical comparison of convergence rates of forward-backward, Douglas-Rachford, and Peaceman-Rachford algorithms for minimizing the sum of a convex proper lower semicontinuous function and a strongly convex differentiable function with Lipschitz continuous gradient. Our results extend the comparison made in [1], when both functions are smooth, to the context where only one is assumed differentiable. Optimal step-sizes and rates of the three algorithms are compared theoretically and numerically in the context of texture segmentation problem, obtaining very sharp estimations and illustrating the high efficiency of Peaceman-Rachford splitting.</p>
        <p><strong><a href=""></a></strong></p>

        <p class="text-danger"><strong> </strong></p>
        <p> </p>
      </div>

      <div class="col">

        <div class="well">
          <p><em>L.M. Briceño-Arias and N. Pustelnik</em></p>
          <pubtit>Convergence rate comparison of proximal algorithms for non-smooth convex optimization with an application to texture segmentation</pubtit>
          <p><img src="http://localhost:4000/images/pubpic/SPL_2022b.png" class="img-responsive" width="30%" style="float: left" /></p>
          <p>In this paper we provide a theoretical and numerical comparison of convergence rates of forward-backward, Douglas-Rachford, and Peaceman-Rachford algorithms for minimizing the sum of a convex proper lower semicontinuous function and a strongly convex differentiable function with Lipschitz continuous gradient. Our results extend the comparison made in [1], when both functions are smooth, to the context where only one is assumed differentiable. Optimal step-sizes and rates of the three algorithms are compared theoretically and numerically in the context of texture segmentation problem, obtaining very sharp estimations and illustrating the high efficiency of Peaceman-Rachford splitting.</p>
          <p><strong><a href=""></a></strong></p>

          <p class="text-danger"><strong> </strong></p>
          <p> </p>
        </div>

        <div class="col">

          <div class="well">
            <p><em>B. Pascal, S. Vaiter, N. Pustelnik, and P. Abry</em></p>
            <pubtit>Automated data-driven selection of the hyperparameters for Total-Variation based texture segmentation</pubtit>
            <p><img src="http://localhost:4000/images/pubpic/JMIV2021.png" class="img-responsive" width="30%" style="float: left" /></p>
            <p>Penalized Least Squares are widely used in signal and image processing. Yet, it suffers from a major limitation since it requires fine-tuning of the regularization parameters. Under assumptions on the noise probability distribution, Stein-based approaches provide unbiased estimator of the quadratic risk. The Generalized Stein Unbiased Risk Estimator is revisited to handle correlated Gaussian noise without requiring to invert the covariance matrix. Then, in order to avoid expansive grid search, it is necessary to design algorithmic scheme minimizing the quadratic risk with respect to regularization parameters. This work extends the Stein’s Unbiased GrAdient estimator of the Risk of Deledalle et al. to the case of correlated Gaussian noise, deriving a general automatic tuning of regularization parameters. First, the theoretical asymptotic unbiasedness of the gradient estimator is demonstrated in the case of general correlated Gaussian noise. Then, the proposed parameter selection strategy is particularized to fractal texture segmentation, where problem formulation naturally entails inter-scale and spatially correlated noise. Numerical assessment is provided, as well as discussion of the practical issues.</p>
            <p><strong><a href=""></a></strong></p>

            <p class="text-danger"><strong> </strong></p>
            <p> </p>
          </div>

          <div class="col">

            <div class="well">
              <p><em>B. Pascal, N. Pustelnik, and P. Abry</em></p>
              <pubtit>Strongly Convex Optimization for Joint Fractal Feature Estimation and Texture Segmentation</pubtit>
              <p><img src="http://localhost:4000/images/pubpic/ACHA2021.png" class="img-responsive" width="30%" style="float: left" /></p>
              <p>The present work investigates the segmentation of textures by formulating it as a strongly convex optimization problem, aiming to favor piecewise constancy of fractal features (local variance and local regularity) widely used to model real-world textures in numerous applications very different in nature. Two objective functions combining these two features are compared, referred to as joint and coupled, promoting either independent or co-localized changes in local variance and regularity. To solve the resulting convex nonsmooth optimization problems, because the processing of large size images and databases are targeted, two categories of proximal algorithms (dual forward-backward and primal-dual), are devised and compared. An in-depth study of the objective functions, notably of their strong convexity, memory and computational costs, permits to propose significantly accelerated algorithms. A class of synthetic models of piecewise fractal texture is constructed and studied. They enable, by means of large-scale Monte-Carlo simulations, to quantify the benefits in texture segmentation of combining local regularity and local variance (as opposed to regularity only) while using strong-convexity accelerated primal-dual algorithms. Achieved results also permit to discuss the gains/costs in imposing co-localizations of changes in local regularity and local variance in the problem formulation. Finally, the potential of the proposed approaches is illustrated on real-world textures taken from a publicly available and documented database.</p>
              <p><strong><a href=""></a></strong></p>

              <p class="text-danger"><strong> </strong></p>
              <p> </p>
            </div>

            <div class="col">

              <div class="well">
                <p><em>M. Jiu and N. Pustelnik</em></p>
                <pubtit>A deep primal-dual proximal network for image restoration</pubtit>
                <p><img src="http://localhost:4000/images/pubpic/JSTSP2021.png" class="img-responsive" width="30%" style="float: left" /></p>
                <p>Image restoration remains a challenging task in image processing. Numerous methods tackle this problem, often solved by minimizing a non-smooth penalized co-log-likelihood function. Although the solution is easily interpretable with theoretic guarantees, its estimation relies on an optimization process that can take time. Considering the research effort in deep learning for image classification and segmentation, this class of methods offers a serious alternative to perform image restoration but stays challenging to solve inverse problems. In this work, we design a deep network, named DeepPDNet, built from primal-dual proximal iterations associated with the minimization of a standard penalized likelihood with an analysis prior, allowing us to take advantage of both worlds. We reformulate a specific instance of the Condat-Vu primal-dual hybrid gradient (PDHG) algorithm as a deep network with fixed layers. The learned parameters are both the PDHG algorithm step-sizes and the analysis linear operator involved in the penalization (including the regularization parameter). These parameters are allowed to vary from a layer to another one. Two different learning strategies “Full learning” and “Partial learning” are proposed, the first one is the most efficient numerically while the second one relies on standard constraints ensuring convergence in the standard PDHG iterations. Moreover, global and local sparse analysis prior are studied to seek a better feature representation. We apply the proposed methods to image restoration on the MNIST and BSD68 datasets and to single image super-resolution on the BSD100 and SET14 datasets. Extensive results show that the proposed DeepPDNet demonstrates excellent performance on the MNIST and the more complex BSD68, BSD100, and SET14 datasets for image restoration and single image super-resolution task</p>
                <p><strong><a href=""></a></strong></p>

                <p class="text-danger"><strong> </strong></p>
                <p> </p>
              </div>

              <div class="col">

                <div class="well">
                  <p><em>B. Pascal, N. Pustelnik, P. Abry, J.-C. Géminard , V. Vidal</em></p>
                  <pubtit>Parameter-free and fast nonlinear piecewise fitering. Application to experimental physics</pubtit>
                  <p><img src="http://localhost:4000/images/pubpic/" class="img-responsive" width="30%" style="float: left" /></p>
                  <p>Numerous fields of nonlinear physics, very different in nature, produce signals and images, that share the common feature of being essentially constituted of piecewise homogeneous phases. Analyzing signals and images from corresponding experiments to construct relevant physical interpretations thus often requires detecting such phases and estimating accurately their characteristics (borders, feature differences, …). However, situations of physical relevance often comes with low to very low signal to noise ratio precluding the standard use of classical linear filtering for analysis and denoising and thus calling for the design of advanced nonlinear signal/image filtering techniques. Additionally, when dealing with experimental physics signals/images, a second limitation is the large amount of data that need to be analyzed to yield accurate and relevant conclusions requiring the design of fast algorithms. The present work proposes a unified signal/image nonlinear filtering procedure, with fast algorithms and a data-driven automated hyperparameter tuning, based on proximal algorithms and Stein unbiased estimator principles. The interest and potential of these tools are illustrated at work on low-confinement solid friction signals and porous media multiphase flows.</p>
                  <p><strong><a href=""></a></strong></p>

                  <p class="text-danger"><strong> </strong></p>
                  <p> </p>
                </div>

                <div class="col">

                  <div class="well">
                    <p><em>M. Foare, N. Pustelnik, and L. Condat</em></p>
                    <pubtit>Semi-linearized proximal alternating minimization for a discrete Mumford-Shah model</pubtit>
                    <p><img src="http://localhost:4000/images/pubpic/TIP2019.png" class="img-responsive" width="30%" style="float: left" /></p>
                    <p>The Mumford-Shah model is a standard model in image segmentation, and due to its difficulty, many approximations have been proposed. The major interest of this functional is to enable joint image restoration and contour detection. In this work, we propose a general formulation of the discrete counterpart of the Mumford-Shah functional, adapted to nonsmooth penalizations, fitting the assumptions required by the Proximal Alternating Linearized Minimization (PALM), with convergence guarantees. A second contribution aims to relax some assumptions on the involved functionals and derive a novel Semi-Linearized Proximal Alternated Minimization (SL-PAM) algorithm, with proved convergence. We compare the performances of the algorithm with several nonsmooth penalizations, for Gaussian and Poisson denoising, image restoration and RGB-color denoising. We compare the results with state-of-the-art convex relaxations of the Mumford-Shah functional, and a discrete version of the Ambrosio-Tortorelli functional. We show that the SL-PAM algorithm is faster than the original PALM algorithm, and leads to competitive denoising, restoration and segmentation results.</p>
                    <p><strong><a href=""></a></strong></p>

                    <p class="text-danger"><strong> </strong></p>
                    <p> </p>
                  </div>

                  <div class="col">

                    <div class="well">
                      <p><em>Y. Kaloga, M. Foare, N. Pustelnik, and P. Jensen</em></p>
                      <pubtit>Discrete Mumford-Shah on graph for mixing matrix estimation</pubtit>
                      <p><img src="http://localhost:4000/images/pubpic/SPL2019.png" class="img-responsive" width="30%" style="float: left" /></p>
                      <p>The discrete Mumford-Shah formalism has been introduced for the image denoising problem, allowing to capture both smooth behavior inside an object and sharp transitions on the boundary. In this letter, we propose first to extend this formalism to graphs and to the problem of mixing matrix estimation. New algorithmic schemes with convergence guarantees relying on proximal alternating minimization strategies are derived, and their efficiency (good estimation and robustness to initialization) is evaluated on simulated data, in the context of vote transfer matrix estimation.</p>
                      <p><strong><a href=""></a></strong></p>

                      <p class="text-danger"><strong> </strong></p>
                      <p> </p>
                    </div>

                    <p>   </p>

                    <!--
## Full List



  Proximal based strategies for solving discrete Mumford-Shah with Ambrosio-Tortorelli penalization on edges <br />
  <em>Hoang Trieu Vy Le, Marion Foare, Nelly Pustelnik </em><br /><a href="https://ieeexplore.ieee.org/abstract/document/9723590">[pdf]</a>



  Hyperparameter selection for the Discrete Mumford-Shah functional <br />
  <em>C.G. Lucas, B. Pascal, N. Pustelnik, and P. Abry </em><br /><a href="">Signal, Image and Video Processing, pp.1-8, Dec. 2022.</a>



  Theoretical and numerical comparison of first order algorithms for cocoercive equations and smooth convex optimization <br />
  <em>L. M. Briceño-Arias and N. Pustelnik </em><br /><a href=""></a>



  Convergence rate comparison of proximal algorithms for non-smooth convex optimization with an application to texture segmentation <br />
  <em>L.M. Briceño-Arias and N. Pustelnik </em><br /><a href=""></a>



  Automated data-driven selection of the hyperparameters for Total-Variation based texture segmentation <br />
  <em>B. Pascal, S. Vaiter, N. Pustelnik, and P. Abry </em><br /><a href=""></a>



  Strongly Convex Optimization for Joint Fractal Feature Estimation and Texture Segmentation <br />
  <em>B. Pascal, N. Pustelnik, and P. Abry </em><br /><a href=""></a>



  A deep primal-dual proximal network for image restoration <br />
  <em>M. Jiu and N. Pustelnik </em><br /><a href=""></a>



  Parameter-free and fast nonlinear piecewise fitering. Application to experimental physics <br />
  <em>B. Pascal, N. Pustelnik, P. Abry, J.-C. Géminard , V. Vidal </em><br /><a href=""></a>



  Semi-linearized proximal alternating minimization for a discrete Mumford-Shah model <br />
  <em>M. Foare, N. Pustelnik, and L. Condat </em><br /><a href=""></a>



  Discrete Mumford-Shah on graph for mixing matrix estimation <br />
  <em>Y. Kaloga, M. Foare, N. Pustelnik, and P. Jensen </em><br /><a href=""></a>


-->
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

</div>

      </div>
    </div>

    <!-- <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-4">
			
		  <p>&copy 2023 ANR Multisc'in. Site made with <a href="https://jekyllrb.com">Jekyll</a> </p>
            

		   <p>  </p><p>
            		  
            
		</div>
		<div class="col-sm-4">
		  Contact:<br />
		  <br />
		  <br />
		  , France<br />
            (<a href="https://www.imt-atlantique.fr/en/school/campuses/brest-campus">Directions</a>)
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script> -->


  </body>

</html>
